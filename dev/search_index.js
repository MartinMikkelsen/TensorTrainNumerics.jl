var documenterSearchIndex = {"docs":
[{"location":"resources/#Resources","page":"Resources","title":"Resources","text":"","category":"section"},{"location":"resources/#Papers-and-Articles","page":"Resources","title":"Papers and Articles","text":"","category":"section"},{"location":"resources/","page":"Resources","title":"Resources","text":"Tensor trains for high-dimensional problems by Mi-Song Dupuy\nFast and Flexible Quantum-Inspired PDE Solvers with Data Integration\nMultiscale interpolative construction of quantized tensor trains\nDirect interpolative construction of the discrete Fourier transform as a matrix product operator","category":"page"},{"location":"resources/#Software-and-Libraries","page":"Resources","title":"Software and Libraries","text":"","category":"section"},{"location":"resources/","page":"Resources","title":"Resources","text":"Scikit-TT\nKrylovKit.jl","category":"page"},{"location":"theory/#Tensor-trains","page":"Tensor trains","title":"Tensor trains","text":"","category":"section"},{"location":"theory/#Table-of-Contents","page":"Tensor trains","title":"Table of Contents","text":"","category":"section"},{"location":"theory/","page":"Tensor trains","title":"Tensor trains","text":"Basics\nMultiplication\nTensor Train Operator times Tensor Train Vector\nTensor Train Operator times Tensor Train Operator\nAddition\nConcatenation\nMatricization\nVisualization\nTensor Train Decomposition\nExample with Tolerance\nOptimization\nALS\nMALS\nDMRG","category":"page"},{"location":"theory/#Basics","page":"Tensor trains","title":"Basics","text":"","category":"section"},{"location":"theory/#Multiplication","page":"Tensor trains","title":"Multiplication","text":"","category":"section"},{"location":"theory/#Tensor-train-operator-times-tensor-train-vector","page":"Tensor trains","title":"Tensor train operator times tensor train vector","text":"","category":"section"},{"location":"theory/","page":"Tensor trains","title":"Tensor trains","text":"To multiply a tensor train operator (TToperator) by a tensor train vector (TTvector), use the * operator.","category":"page"},{"location":"theory/","page":"Tensor trains","title":"Tensor trains","text":"using TensorTrainNumerics\n\n# Define the dimensions and ranks for the TTvector\ndims = (2, 2, 2)\nrks = [1, 2, 2, 1]\n\n# Create a random TTvector\ntt_vec = rand_tt(dims, rks)\n\n# Define the dimensions and ranks for the TToperator\nop_dims = (2, 2, 2)\nop_rks = [1, 2, 2, 1]\n\n# Create a random TToperator\ntt_op = rand_tto(op_dims, 3)\n\n# Perform the multiplication\nresult = tt_op * tt_vec\n\n# Visualize the result\nvisualize(result)","category":"page"},{"location":"theory/#Tensor-train-operator-times-tensor-train-operator","page":"Tensor trains","title":"Tensor train operator times tensor train operator","text":"","category":"section"},{"location":"theory/","page":"Tensor trains","title":"Tensor trains","text":"To multiply two tensor train operators, use the * operator.","category":"page"},{"location":"theory/","page":"Tensor trains","title":"Tensor trains","text":"# Create another random TToperator\ntt_op2 = rand_tto(op_dims, 3)\n\n# Perform the multiplication\nresult_op = tt_op * tt_op2\n\n# Visualize the result\nvisualize(result_op)","category":"page"},{"location":"theory/#Addition","page":"Tensor trains","title":"Addition","text":"","category":"section"},{"location":"theory/","page":"Tensor trains","title":"Tensor trains","text":"To add two tensor train vectors or operators, use the + operator.","category":"page"},{"location":"theory/","page":"Tensor trains","title":"Tensor trains","text":"# Create another random TTvector\ntt_vec2 = rand_tt(dims, rks)\n\n# Perform the addition\nresult_add = tt_vec + tt_vec2\n\n# Visualize the result\nvisualize(result_add)","category":"page"},{"location":"theory/#Concatenation","page":"Tensor trains","title":"Concatenation","text":"","category":"section"},{"location":"theory/","page":"Tensor trains","title":"Tensor trains","text":"To concatenate two tensor train vectors or operators, use the concatenate function.","category":"page"},{"location":"theory/","page":"Tensor trains","title":"Tensor trains","text":"# Concatenate two TTvectors\nresult_concat = concatenate(tt_vec, tt_vec2)\n\n# Visualize the result\nvisualize(result_concat)","category":"page"},{"location":"theory/#Matricization","page":"Tensor trains","title":"Matricization","text":"","category":"section"},{"location":"theory/","page":"Tensor trains","title":"Tensor trains","text":"To convert a tensor train vector or operator into its matrix form, use the matricize function.","category":"page"},{"location":"theory/","page":"Tensor trains","title":"Tensor trains","text":"# Matricize the TTvector\nresult_matrix = matricize(tt_vec, 3)\n\n# Print the result\nprintln(result_matrix)","category":"page"},{"location":"theory/#Visualization","page":"Tensor trains","title":"Visualization","text":"","category":"section"},{"location":"theory/","page":"Tensor trains","title":"Tensor trains","text":"To visualize a tensor train vector or operator, use the visualize function.","category":"page"},{"location":"theory/","page":"Tensor trains","title":"Tensor trains","text":"# Visualize the TTvector\nvisualize(tt_vec)","category":"page"},{"location":"theory/#Tensor-Train-Decomposition","page":"Tensor trains","title":"Tensor Train Decomposition","text":"","category":"section"},{"location":"theory/","page":"Tensor trains","title":"Tensor trains","text":"The ttv_decomp function performs a tensor train decomposition on a given tensor.","category":"page"},{"location":"theory/","page":"Tensor trains","title":"Tensor trains","text":"using TensorTrainNumerics\n\n# Define a 3-dimensional tensor\ntensor = rand(2, 3, 4)\n\n# Perform the tensor train decomposition\nttv = ttv_decomp(tensor)\n\n# Print the TTvector ranks\nprintln(ttv.ttv_rks)","category":"page"},{"location":"theory/#Explanation","page":"Tensor trains","title":"Explanation","text":"","category":"section"},{"location":"theory/","page":"Tensor trains","title":"Tensor trains","text":"The ttv_decomp function takes a tensor as input and returns its tensor train decomposition in the form of a TTvector. The decomposition is performed using the Hierarchical SVD algorithm, which decomposes the tensor into a series of smaller tensors (cores) connected by ranks.","category":"page"},{"location":"theory/#Example-with-Tolerance","page":"Tensor trains","title":"Example with Tolerance","text":"","category":"section"},{"location":"theory/","page":"Tensor trains","title":"Tensor trains","text":"using TensorTrainNumerics\n\n# Define a 3-dimensional tensor\ntensor = rand(2, 3, 4)\n\n# Perform the tensor train decomposition with a custom tolerance\nttv = ttv_decomp(tensor, tol=1e-10)\n\n# Print the TTvector ranks\nprintln(ttv.ttv_rks)","category":"page"},{"location":"theory/#Optimization","page":"Tensor trains","title":"Optimization","text":"","category":"section"},{"location":"theory/#ALS","page":"Tensor trains","title":"ALS","text":"","category":"section"},{"location":"theory/","page":"Tensor trains","title":"Tensor trains","text":"using TensorTrainNumerics\n\n# Define the dimensions and ranks for the TTvector\ndims = (2, 2, 2)\nrks = [1, 2, 2, 1]\n\n# Create a random TTvector for the initial guess\ntt_start = rand_tt(dims, rks)\n\n# Create a random TToperator for the matrix A\nA_dims = (2, 2, 2)\nA_rks = [1, 2, 2, 1]\nA = rand_tto(A_dims, 3)\n\n# Create a random TTvector for the right-hand side b\nb = rand_tt(dims, rks)\n\n# Solve the linear system Ax = b using the ALS algorithm\ntt_opt = als_linsolve(A, b, tt_start; sweep_count=2)\n\n# Print the optimized TTvector\nprintln(tt_opt)\n\n# Define the sweep schedule and rank schedule for the eigenvalue problem\nsweep_schedule = [2, 4]\nrmax_schedule = [2, 3]\n\n# Solve the eigenvalue problem using the ALS algorithm\neigenvalues, tt_eigvec = als_eigsolve(A, tt_start; sweep_schedule=sweep_schedule, rmax_schedule=rmax_schedule)\n\n# Print the lowest eigenvalue and the corresponding eigenvector\nprintln(\"Lowest eigenvalue: \", eigenvalues[end])\nprintln(\"Corresponding eigenvector: \", tt_eigvec)","category":"page"},{"location":"theory/#MALS","page":"Tensor trains","title":"MALS","text":"","category":"section"},{"location":"theory/","page":"Tensor trains","title":"Tensor trains","text":"using TensorTrainNumerics\n\ndims = (2, 2, 2)\nrks = [1, 2, 2, 1]\n\n# Create a random TTvector for the initial guess\ntt_start = rand_tt(dims, rks)\n\n# Create a random TToperator for the matrix A\nA_dims = (2, 2, 2)\nA_rks = [1, 2, 2, 1]\nA = rand_tto(A_dims, 3)\n\n# Create a random TTvector for the right-hand side b\nb = rand_tt(dims, rks)\n\n# Solve the linear system Ax = b using the MALS algorithm\ntt_opt = mals_linsolve(A, b, tt_start; tol=1e-12, rmax=4)\n\n# Print the optimized TTvector\nprintln(tt_opt)\n\n# Define the sweep schedule and rank schedule for the eigenvalue problem\nsweep_schedule = [2, 4]\nrmax_schedule = [2, 3]\n\n# Solve the eigenvalue problem using the MALS algorithm\neigenvalues, tt_eigvec, r_hist = mals_eigsolve(A, tt_start; tol=1e-12, sweep_schedule=sweep_schedule, rmax_schedule=rmax_schedule)\n\n# Print the lowest eigenvalue and the corresponding eigenvector\nprintln(\"Lowest eigenvalue: \", eigenvalues[end])\nprintln(\"Corresponding eigenvector: \", tt_eigvec)\nprintln(\"Rank history: \", r_hist)","category":"page"},{"location":"theory/#DMRG","page":"Tensor trains","title":"DMRG","text":"","category":"section"},{"location":"theory/","page":"Tensor trains","title":"Tensor trains","text":"using TensorTrainNumerics\n\ndims = (2, 2, 2)\nrks = [1, 2, 2, 1]\n\n# Create a random TTvector for the initial guess\ntt_start = rand_tt(dims, rks)\n\n# Create a random TToperator for the matrix A\nA_dims = (2, 2, 2)\nA_rks = [1, 2, 2, 1]\nA = rand_tto(A_dims, 3)\n\n# Create a random TTvector for the right-hand side b\nb = rand_tt(dims, rks)\n\n# Solve the linear system Ax = b using the DMRG algorithm\ntt_opt = dmrg_linsolve(A, b, tt_start; sweep_count=2, N=2, tol=1e-12)\n\n# Print the optimized TTvector\nprintln(tt_opt)\n\n# Define the sweep schedule and rank schedule for the eigenvalue problem\nsweep_schedule = [2, 4]\nrmax_schedule = [2, 3]\n\n# Solve the eigenvalue problem using the DMRG algorithm\neigenvalues, tt_eigvec, r_hist = dmrg_eigsolve(A, tt_start; N=2, tol=1e-12, sweep_schedule=sweep_schedule, rmax_schedule=rmax_schedule)\n\n# Print the lowest eigenvalue and the corresponding eigenvector\nprintln(\"Lowest eigenvalue: \", eigenvalues[end])\nprintln(\"Corresponding eigenvector: \", tt_eigvec)\nprintln(\"Rank history: \", r_hist)","category":"page"},{"location":"examples/#Examples","page":"Examples","title":"Examples","text":"","category":"section"},{"location":"examples/#Partial-differential-equations","page":"Examples","title":"Partial differential equations","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"Let's consider the following 2D partial differential equation ","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"Delta u(xy) = f(xy)","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"where Delta is the Laplacian operator, u(xy) is the unknown function, and f(xy) is a given function. In this example we assume f(xy)=0 using Dirichlet-Dirichlet boundary conditions given by u(0y) = cos(pi y), u(1y) = sin(y).","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"We want to solve this equation using quantics tensor trains (QTTs).  We start by defining the dimensions and the resolution of the grid. Lets say we want 2^10 points in each dimension, which gives us a grid of 1024 times 1024 points on a 01times 01 grid. ","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"using TensorTrainNumerics\nusing CairoMakie\n\ncores = 10\na = 0.0\nb = 1.0","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"We follow the same convention as in this paper where we define the finite difference operator using the following inputs","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"h = (b-a)/(2^cores)\np = 1.0\ns = 0.0\nv = 0.0\nα = h^2*v-2*p\nβ = p + h*s/2\nγ = p-h*s/2\n\nΔ = toeplitz_to_qtto(α, β, γ, cores) ","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"To get the 2D Laplacian operator, we need to take the Kronecker product of the 1D Laplacian operator with the identity. ","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"A = Δ ⊗ id_tto(cores) + id_tto(cores) ⊗ Δ","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"To build the boundary vector we take the Kronecker product with the QTT basis vectors and define some random initial guess for the solution. ","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"b = qtt_cos(cores) ⊗ qtt_basis_vector(cores, 1) + qtt_sin(cores) ⊗ qtt_basis_vector(cores, 2^cores) \ninitial_guess = rand_tt(b.ttv_dims, b.ttv_rks)","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"We solve the linear system using DMRG","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"x_dmrg = dmrg_linsolve(A, b, initial_guess; sweep_count=50,tol=1e-15)","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"And we reshape the solution to a 2D array for visualization","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"\nsolution = reshape(qtt_to_function(x_dmrg), 2^cores, 2^cores)\nxes = collect(range(0,1,length=2^cores))\nyes = collect(range(0,1,length=2^cores))\nfig = Figure()\ncmap = :roma\nax = Axis(fig[1, 1], title = \"Laplace Solution\", xlabel = \"x\", ylabel = \"y\")\nhm = heatmap!(ax, xes, yes, solution; colormap = cmap)\nColorbar(fig[1, 2], hm, label = \"u(x, y)\")\nfig","category":"page"},{"location":"examples/#Time-stepping","page":"Examples","title":"Time-stepping","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"We can also solve time-dependent PDEs using the QTT framework. In this exampl we will use the explicit Euler method, the implicit Euler method and the Crank-Nicolson scheme.","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"using TensorTrainNumerics\nusing CairoMakie\n\ncores = 8\nh = 1/cores^2\nA = h^2*toeplitz_to_qtto(-2,1.0,1.0,cores)\nxes = collect(range(0.0, 1.0, 2^cores))\n\nu₀ = qtt_sin(cores,λ=π)\ninit = rand_tt(u₀.ttv_dims, u₀.ttv_rks)\nsteps = collect(range(0.0,10.0,1000))\nsolution_explicit, error_explicit = euler_method(A, u₀, steps; return_error=true)\n\nsolution_implicit, rel_implicit = implicit_euler_method(A, u₀, init, steps; return_error=true)\n\nsolution_crank, rel_crank = crank_nicholson_method(A, u₀, init, steps; return_error=true, tt_solver=\"mals\")\n\nfig = Figure()\nax = Axis(fig[1, 1], xlabel = \"x\", ylabel = \"u(x)\", title = \"Comparison of Time-Stepping Methods\")\nlines!(ax, xes, qtt_to_function(solution_explicit), label = \"Explicit Euler\", linestyle = :solid, linewidth=3)\nlines!(ax, xes, qtt_to_function(solution_implicit), label = \"Implicit Euler\", linestyle = :dot, linewidth=3)\nlines!(ax, xes, qtt_to_function(solution_crank), label = \"Crank-Nicolson\", linestyle = :dash, linewidth=3)\naxislegend(ax)\nfig","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"And print the relative errors","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"println(\"Relative error for explicit Euler: \", error_explicit)\nprintln(\"Relative error for implicit Euler: \", rel_implicit)\nprintln(\"Relative error for Crank-Nicolson: \", rel_crank)","category":"page"},{"location":"examples/#Discrete-Fourier-Transform","page":"Examples","title":"Discrete Fourier Transform","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"Based on this paper we also have access to the discrete Fourier transform (DFT) in QTT format. Below is an esample of how to use it. You can use the fourier_qtto function to create a QTT representation of the Fourier transform operator where the sign parameter determines if its the Fourier transform or the inverse Fourier transform. ","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"using TensorTrainNumerics   \nusing Random \n\nd = 10\nN = 2^d\nK = 50\nsign = -1.0\nnormalize = true\n\nRandom.seed!(1234)\nr = 12\ncoeffs = randn(r) .+ 1im * randn(r)\n\nf(x) = sum(coeffs .* cispi.(2 .* (0:(r - 1)) .* x))\n\nF = fourier_qtto(d; K = K, sign = -1.0, normalize = true)\nx_qtt = function_to_qtt_uniform(f, d)\ny_qtt = F * x_qtt","category":"page"},{"location":"#TensorTrainNumerics.jl","page":"TensorTrainNumerics.jl","title":"TensorTrainNumerics.jl","text":"","category":"section"},{"location":"","page":"TensorTrainNumerics.jl","title":"TensorTrainNumerics.jl","text":"Tensor Train Numerics is a Julia package designed to provide efficient numerical methods for working with tensor trains (TT) and quantized tensor trains (QTT). This package offers a comprehensive set of tools for constructing, manipulating, and performing operations on tensor trains, which are useful in various scientific and engineering applications, including high-dimensional data analysis, machine learning, and computational physics.","category":"page"},{"location":"#Key-features","page":"TensorTrainNumerics.jl","title":"Key features","text":"","category":"section"},{"location":"","page":"TensorTrainNumerics.jl","title":"TensorTrainNumerics.jl","text":"Tensor Train Decomposition: Efficient algorithms for decomposing high-dimensional tensors into tensor train format, reducing computational complexity and memory usage.\nTensor Operations: Support for basic tensor operations such as addition, multiplication, and contraction in tensor train format.\nDiscrete Operators: Implementation of discrete Laplacians, gradient operators, and shift matrices in tensor train format for solving partial differential equations and other numerical problems.\nQuantized Tensor Trains: Tools for constructing and manipulating quantized tensor trains, which provide further compression and efficiency for large-scale problems.\nIterative Solvers: Integration with iterative solvers for solving linear systems and eigenvalue problems in tensor train format.\nVisualization: Basic visualization tools for inspecting tensor train structures and their properties. ","category":"page"},{"location":"#Getting-started","page":"TensorTrainNumerics.jl","title":"Getting started","text":"","category":"section"},{"location":"","page":"TensorTrainNumerics.jl","title":"TensorTrainNumerics.jl","text":"To get started with Tensor Train Numerics, you can install the package using Julia's package manager:","category":"page"},{"location":"","page":"TensorTrainNumerics.jl","title":"TensorTrainNumerics.jl","text":"using Pkg\nPkg.add(\"TensorTrainNumerics\")","category":"page"},{"location":"#Basic-example","page":"TensorTrainNumerics.jl","title":"Basic example","text":"","category":"section"},{"location":"","page":"TensorTrainNumerics.jl","title":"TensorTrainNumerics.jl","text":"using TensorTrainNumerics\n\n# Define the dimensions and ranks for the TTvector\ndims = (2, 2, 2)\nrks = [1, 2, 2, 1]\n\n# Create a random TTvector\ntt_vec = rand_tt(dims, rks)\n\n# Define the dimensions and ranks for the TToperator\nop_dims = (2, 2, 2)\nop_rks = [1, 2, 2, 1]\n\n# Create a random TToperator\ntt_op = rand_tto(op_dims, 3)\n\n# Perform the multiplication\nresult = tt_op * tt_vec\n\n# Visualize the result\n\nvisualize(result)","category":"page"},{"location":"","page":"TensorTrainNumerics.jl","title":"TensorTrainNumerics.jl","text":"And we can print the result","category":"page"},{"location":"","page":"TensorTrainNumerics.jl","title":"TensorTrainNumerics.jl","text":"println(result)","category":"page"},{"location":"","page":"TensorTrainNumerics.jl","title":"TensorTrainNumerics.jl","text":"We can also unfold this","category":"page"},{"location":"","page":"TensorTrainNumerics.jl","title":"TensorTrainNumerics.jl","text":"matricize(result, 3)","category":"page"},{"location":"#Interpolation","page":"TensorTrainNumerics.jl","title":"Interpolation","text":"","category":"section"},{"location":"","page":"TensorTrainNumerics.jl","title":"TensorTrainNumerics.jl","text":"We can also do interpolation in the QTT framework:","category":"page"},{"location":"","page":"TensorTrainNumerics.jl","title":"TensorTrainNumerics.jl","text":"using CairoMakie\nusing TensorTrainNumerics\n\nf = x -> cos(1 / (x^3 + 0.01)) + sin(π * x)\nnum_cores = 10  \nN = 150 \n\nqtt = interpolating_qtt(f, num_cores, N)\nqtt_rank_revealing = lagrange_rank_revealing(f, num_cores, N)\n\nqtt_values = matricize(qtt, num_cores)\nqtt_values_rank_revealing = matricize(qtt_rank_revealing, num_cores)\n\nx_points = LinRange(0, 1, 2^num_cores)\noriginal_values = f.(x_points)\n\nfig = Figure()\nax = Axis(fig[1, 1], title=\"Function Approximation\", xlabel=\"x\", ylabel=\"f(x)\")\n\nlines!(ax, x_points, original_values, label=\"Original Function\")\nlines!(ax, x_points, qtt_values_rank_revealing, label=\"QTT, rank rev.\", linestyle=:dash, color=:green)\nlines!(ax, x_points, qtt_values, label=\"QTT\", linestyle=:dash, color=:red)\n\naxislegend(ax)\nfig","category":"page"},{"location":"","page":"TensorTrainNumerics.jl","title":"TensorTrainNumerics.jl","text":"We can visualize the interpolating QTT as ","category":"page"},{"location":"","page":"TensorTrainNumerics.jl","title":"TensorTrainNumerics.jl","text":"visualize(qtt)","category":"page"},{"location":"","page":"TensorTrainNumerics.jl","title":"TensorTrainNumerics.jl","text":"And similarly for the rank-revealing","category":"page"},{"location":"","page":"TensorTrainNumerics.jl","title":"TensorTrainNumerics.jl","text":"visualize(qtt_rank_revealing)","category":"page"},{"location":"#Functions","page":"TensorTrainNumerics.jl","title":"Functions","text":"","category":"section"},{"location":"","page":"TensorTrainNumerics.jl","title":"TensorTrainNumerics.jl","text":"You can also use a low-rank representation of any trigonometric function and polynomial.","category":"page"},{"location":"","page":"TensorTrainNumerics.jl","title":"TensorTrainNumerics.jl","text":"using TensorTrainNumerics\nusing CairoMakie\n\nd = 8\n\nA1 = qtt_exp(d)\nA2 = qtt_sin(d, λ = π)\nA3 = qtt_cos(d, λ = π)\nA4 = qtt_polynom([0.0, 2.0, 3.0, -8.0, -5.0], d; a = 0.0, b = 1.0)\n\n\nqtt_values_exponential = qtt_to_function(A1)\nqtt_values_sin = qtt_to_function(A2)\nqtt_values_cos = qtt_to_function(A3)\nqtt_values_polynom = qtt_to_function(A4)\n\n\nvalues_exp(x) = exp(x)\nvalues_sin(x) = sin(x * π^2)\nvalues_cos(x) = cos(x * π^2)\nvalues_polynom(x) = 2 * x + 3 * x^2 - 8 * x^3 - 5 * x^4\n\nx_points = LinRange(0, 1, 2^8)\noriginal_values_exponential = values_exp.(x_points)\noriginal_values_sin = values_sin.(x_points)\noriginal_values_cos = values_cos.(x_points)\noriginal_values_polynom = values_polynom.(x_points)\n\nlet\n    fig = Figure()\n    ax1 = Axis(fig[2, 2], title = \"Exp Approximation\", xlabel = \"x\", ylabel = \"f(x)\")\n    ax2 = Axis(fig[1, 1], title = \"Sin Approximation\", xlabel = \"x\", ylabel = \"f(x)\")\n    ax3 = Axis(fig[1, 2], title = \"Cos Approximation\", xlabel = \"x\", ylabel = \"f(x)\")\n    ax4 = Axis(fig[2, 1], title = \"Polynomial Approximation\", xlabel = \"x\", ylabel = \"f(x)\")\n\n\n    lines!(ax1, x_points, original_values_exponential, label = \"Exponential function\")\n    lines!(ax1, x_points, qtt_values_exponential, label = \"QTT exponential function\", linestyle = :dash, color = :green)\n\n    lines!(ax2, x_points, original_values_sin, label = \"Sine function\")\n    lines!(ax2, x_points, qtt_values_sin, label = \"QTT sine function\", linestyle = :dash, color = :red)\n\n    lines!(ax3, x_points, original_values_cos, label = \"Sine function\")\n    lines!(ax3, x_points, qtt_values_cos, label = \"QTT sine function\", linestyle = :dash, color = :red)\n\n    lines!(ax4, x_points, original_values_polynom, label = \"Sine function\")\n    lines!(ax4, x_points, qtt_values_polynom, label = \"QTT sine function\", linestyle = :dash, color = :red)\n\n    fig\nend","category":"page"},{"location":"API/#API","page":"API","title":"API","text":"","category":"section"}]
}
