var documenterSearchIndex = {"docs":
[{"location":"","page":"-","title":"-","text":"##TensorTrainNumerics.jl","category":"page"},{"location":"","page":"-","title":"-","text":"Tensor Train Numerics is a Julia package designed to provide efficient numerical methods for working with tensor trains (TT) and quantized tensor trains (QTT). This package offers a comprehensive set of tools for constructing, manipulating, and performing operations on tensor trains, which are useful in various scientific and engineering applications, including high-dimensional data analysis, machine learning, and computational physics.","category":"page"},{"location":"#Key-features","page":"-","title":"Key features","text":"","category":"section"},{"location":"","page":"-","title":"-","text":"Tensor Train Decomposition: Efficient algorithms for decomposing high-dimensional tensors into tensor train format, reducing computational complexity and memory usage.\nTensor Operations: Support for basic tensor operations such as addition, multiplication, and contraction in tensor train format.\nDiscrete Operators: Implementation of discrete Laplacians, gradient operators, and shift matrices in tensor train format for solving partial differential equations and other numerical problems.\nQuantized Tensor Trains: Tools for constructing and manipulating quantized tensor trains, which provide further compression and efficiency for large-scale problems.\nIterative Solvers: Integration with iterative solvers for solving linear systems and eigenvalue problems in tensor train format.\nVisualization: Basic visualization tools for inspecting tensor train structures and their properties. ","category":"page"},{"location":"#Getting-started","page":"-","title":"Getting started","text":"","category":"section"},{"location":"","page":"-","title":"-","text":"To get started with Tensor Train Numerics, you can install the package using Julia's package manager:","category":"page"},{"location":"","page":"-","title":"-","text":"using Pkg\nPkg.add(\"TensorTrainNumerics\")","category":"page"},{"location":"#Basic-example","page":"-","title":"Basic example","text":"","category":"section"},{"location":"","page":"-","title":"-","text":"using TensorTrainNumerics\n\n# Define the dimensions and ranks for the TTvector\ndims = (2, 2, 2)\nrks = [1, 2, 2, 1]\n\n# Create a random TTvector\ntt_vec = rand_tt(dims, rks)\n\n# Define the dimensions and ranks for the TToperator\nop_dims = (2, 2, 2)\nop_rks = [1, 2, 2, 1]\n\n# Create a random TToperator\ntt_op = rand_tto(op_dims, 3)\n\n# Perform the multiplication\nresult = tt_op * tt_vec\n\n# Visualize the result\n\nvisualize(result)","category":"page"},{"location":"","page":"-","title":"-","text":"And we can print the result","category":"page"},{"location":"","page":"-","title":"-","text":"println(result)","category":"page"},{"location":"#Interpolation","page":"-","title":"Interpolation","text":"","category":"section"},{"location":"","page":"-","title":"-","text":"We can also do interpolation in the QTT framework:","category":"page"},{"location":"","page":"-","title":"-","text":"\nusing CairoMakie\nusing TensorTrainNumerics\n\nf = x -> cos(1 / (x^3 + 0.01)) + sin(Ï€ * x)\nnum_cores = 10  \nN = 150 \n\nqtt = interpolating_qtt(f, num_cores, N)\nqtt_rank_revealing = lagrange_rank_revealing(f, num_cores, N)\n\nqtt_values = matricize(qtt, num_cores)\nqtt_values_rank_revealing = matricize(qtt_rank_revealing, num_cores)\n\nx_points = LinRange(0, 1, 2^num_cores)\noriginal_values = f.(x_points)\n\nfig = Figure()\nax = Axis(fig[1, 1], title=\"Function Approximation\", xlabel=\"x\", ylabel=\"f(x)\")\n\nlines!(ax, x_points, original_values, label=\"Original Function\")\nlines!(ax, x_points, qtt_values_rank_revealing, label=\"QTT, rank rev.\", linestyle=:dash, color=:green)\nlines!(ax, x_points, qtt_values, label=\"QTT\", linestyle=:dash, color=:red)\n\naxislegend(ax)\nfig","category":"page"}]
}
